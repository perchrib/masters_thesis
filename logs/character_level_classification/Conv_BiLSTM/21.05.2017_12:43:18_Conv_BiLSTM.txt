Training_log - 21/05/2017 12:43:18

Model name: Conv_BiLSTM
Elapsed training time: 11h:51m:06s

Training set size: 587373
Validation set size: 65263
Validation set fraction: 0.098086
Test set fraction: 0.019128

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 50
Max sequence length: 100

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.618375  0.640018  0.663393  0.597158
1   0.662441  0.594249  0.677581  0.573795
2   0.678768  0.575733  0.689717  0.559242
3   0.688617  0.562516  0.699140  0.550783
4   0.696998  0.551442  0.703814  0.549527
5   0.704242  0.542504  0.709115  0.536978
6   0.709667  0.534402  0.711965  0.530891
7   0.715327  0.527428  0.715750  0.528536
8   0.720059  0.520915  0.719474  0.522433
9   0.723493  0.515938  0.722247  0.518055
10  0.727539  0.511131  0.723136  0.517208
11  0.729708  0.507225  0.726415  0.513791
12  0.732235  0.503830  0.728024  0.510979
13  0.734715  0.499923  0.726537  0.514098
14  0.736769  0.497350  0.728560  0.508525
15  0.738308  0.494570  0.730736  0.507308
16  0.740695  0.491499  0.731042  0.506721
17  0.742322  0.489324  0.734030  0.503238
18  0.744304  0.487325  0.734597  0.503406
19  0.745887  0.485062  0.735440  0.503130
20  0.746097  0.484231  0.735578  0.501798
21  0.747579  0.482056  0.734183  0.502511
22  0.748964  0.480071  0.737232  0.500103
23  0.749357  0.479404  0.737799  0.498706
24  0.750504  0.477765  0.736773  0.499309
25  0.752249  0.476086  0.737999  0.500697
26  0.752978  0.474751  0.738841  0.498089
27  0.752689  0.474343  0.737401  0.500355
28  0.753005  0.473654  0.738029  0.498785
29  0.754703  0.471850  0.739822  0.497322
30  0.755723  0.470569  0.739025  0.496656
31  0.756492  0.469590  0.739056  0.497359
32  0.756633  0.469039  0.740021  0.494713
33  0.757592  0.467867  0.741599  0.494553
34  0.757871  0.466978  0.742626  0.495412
35  0.758404  0.466556  0.739914  0.496411
36  0.758046  0.466374  0.741308  0.495986

Validation PRF
                 Female          Male  Overall Macro  Overall Micro
Precision      0.729745      0.750293       0.740019       0.741308
Recall         0.694249      0.781332       0.737790       0.741308
F-score        0.711555      0.765498       0.738526       0.741308
Support    29995.000000  35268.000000            NaN            NaN

--------------Test results---------------
loss: 0.740880 acc: 0.592210

Test PRF
                Female         Male  Overall Macro  Overall Micro
Precision     0.602528     0.580351       0.591440       0.592206
Recall        0.622475     0.559753       0.591114       0.592206
F-score       0.612339     0.569866       0.591103       0.592206
Support    6585.000000  6142.000000            NaN            NaN

--------------Model Diagram---------------
       InputLayer (None, 100)             InputLayer (None, 100)      
           Lambda (None, 100, 94)             Lambda (None, 100, 94)  
           Conv1D (None, 96, 1024)            Conv1D (None, 96, 1024) 
          Dropout (None, 96, 1024)           Dropout (None, 96, 1024) 
     MaxPooling1D (None, 48, 1024)      MaxPooling1D (None, 48, 1024) 
             LSTM (None, 256)                   LSTM (None, 256)      
                  \________________________________/                  
                                  |                                   
                             Merge (None, 512)                        
                           Dropout (None, 512)                        
                             Dense (None, 200)                        
                             Dense (None, 2)                          


Model information:
=========================================
 Kernel_size: 5
 Filters: 1024
 Pool length: 2
 LSTM dropout: 0.200000, LSTM recurrent dropout 0.200000
 Conv dropout: 0.500000
 Dense drop1 0.500000
 Dense drop2 0.200000
Extra information:
=========================================
 Remove stopwords True
 Lemmatize False
 Remove punctuation False
 Remove emoticons True
 Text is not lowercased
 Internet terms have been replaced with placeholders
 Removed 2612 tweet because they were shorter than threshold