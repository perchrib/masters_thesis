Training_log - 22/05/2017 05:14:20

Model name: Conv_BiLSTM
Elapsed training time: 29h:36m:35s

Training set size: 586617
Validation set size: 65179
Validation set fraction: 0.098084
Test set fraction: 0.019152

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 50
Max sequence length: 100

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.610988  0.648531  0.644180  0.616162
1   0.641758  0.618079  0.658019  0.604297
2   0.652663  0.604885  0.663542  0.593045
3   0.660112  0.595611  0.669556  0.589089
4   0.667400  0.588031  0.675187  0.580791
5   0.672284  0.581680  0.677319  0.577603
6   0.677055  0.576341  0.681907  0.573754
7   0.680352  0.571558  0.680756  0.571841
8   0.683818  0.567872  0.685037  0.568826
9   0.686733  0.564053  0.686862  0.568213
10  0.688896  0.560649  0.688289  0.566038
11  0.691214  0.557756  0.688734  0.565003
12  0.693004  0.555802  0.689240  0.562852
13  0.695331  0.552929  0.691496  0.560879
14  0.696589  0.551353  0.692294  0.560502
15  0.697709  0.549593  0.693275  0.558996
16  0.699450  0.548051  0.694871  0.559073
17  0.700888  0.546243  0.694963  0.558053
18  0.701142  0.545226  0.695838  0.557066
19  0.703115  0.543983  0.694518  0.556509
20  0.704088  0.542716  0.696866  0.555942
21  0.704937  0.541041  0.696697  0.555101
22  0.705672  0.540419  0.697525  0.555221
23  0.705696  0.539577  0.697832  0.555094
24  0.706601  0.538851  0.698108  0.554926
25  0.707710  0.537778  0.697142  0.555181
26  0.708873  0.536695  0.697940  0.555172
27  0.708819  0.536318  0.700594  0.552140
28  0.709175  0.535847  0.700226  0.552384
29  0.709277  0.535363  0.700241  0.551904
30  0.709386  0.534661  0.702174  0.552039
31  0.710958  0.533409  0.699643  0.552335
32  0.710724  0.533517  0.700133  0.551724
33  0.710994  0.533296  0.699382  0.553347
34  0.710973  0.533395  0.700931  0.551973
35  0.711185  0.532989  0.699842  0.553310

Validation PRF
                 Female          Male  Overall Macro  Overall Micro
Precision      0.680488      0.715113       0.697801       0.699842
Recall         0.653352      0.739344       0.696348       0.699842
F-score        0.666644      0.727027       0.696835       0.699842
Support    29941.000000  35238.000000            NaN            NaN

--------------Test results---------------
loss: 0.744650 acc: 0.593230

Test PRF
                Female         Male  Overall Macro  Overall Micro
Precision     0.608508     0.577336       0.592922       0.593227
Recall        0.599544     0.586454       0.592999       0.593227
F-score       0.603993     0.581859       0.592926       0.593227
Support    6585.000000  6142.000000            NaN            NaN

--------------Model Diagram---------------
       InputLayer (None, 100)             InputLayer (None, 100)      
           Lambda (None, 100, 77)             Lambda (None, 100, 77)  
           Conv1D (None, 96, 1024)            Conv1D (None, 96, 1024) 
          Dropout (None, 96, 1024)           Dropout (None, 96, 1024) 
     MaxPooling1D (None, 32, 1024)      MaxPooling1D (None, 32, 1024) 
             LSTM (None, 256)                   LSTM (None, 256)      
                  \________________________________/                  
                                  |                                   
                             Merge (None, 512)                        
                           Dropout (None, 512)                        
                             Dense (None, 200)                        
                             Dense (None, 2)                          


Model information:
=========================================
 Kernel_size: 5
 Filters: 1024
 Pool length: 3
 LSTM dropout: 0.200000, LSTM recurrent dropout 0.200000
 Conv dropout: 0.500000
 Dense drop1 0.500000
 Dense drop2 0.200000
Extra information:
=========================================
 Remove stopwords True
 Lemmatize False
 Remove punctuation False
 Remove emoticons True
 Internet terms have been replaced with placeholders
 Removed 3452 tweet because they were shorter than threshold