Training_log - 27/04/2017 21:06:48

Model name: Conv_BiLSTM
Elapsed training time: 285 minutes

Training set size: 530222
Validation set size: 66277
Validation set fraction: 0.099999
Test set fraction: 0.099999

Hyperparameters
=========================================
Optimizer: adam
Batch size: 256
Max number of epochs: 50
Max sequence length: 80

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.612547  0.649494  0.644643  0.619793
1   0.643463  0.618742  0.654707  0.606230
2   0.656338  0.603434  0.660893  0.594989
3   0.665042  0.593021  0.668301  0.588844
4   0.672173  0.583853  0.667185  0.587880
5   0.678214  0.576673  0.674608  0.578792
6   0.683900  0.569627  0.677007  0.576286
7   0.688706  0.563698  0.681684  0.571790
8   0.692093  0.558231  0.684596  0.568024
9   0.697442  0.551941  0.685698  0.566880
10  0.701501  0.546002  0.687116  0.563853
11  0.705448  0.541024  0.691130  0.560252
12  0.708882  0.535669  0.690692  0.558840
13  0.712933  0.531544  0.692473  0.560319
14  0.715561  0.527399  0.692835  0.557716
15  0.719278  0.522345  0.695807  0.555378
16  0.722692  0.518166  0.697044  0.556060
17  0.725860  0.514468  0.700680  0.554073
18  0.728578  0.510416  0.700409  0.551937
19  0.730800  0.506667  0.701133  0.553169
20  0.732989  0.504270  0.703502  0.554350
21  0.735437  0.500031  0.703713  0.553975

--------------Test results---------------
loss: 0.558230acc: 0.702040

--------------Model Diagram---------------
       InputLayer (None, 80)              InputLayer (None, 80)       
           Lambda (None, 80, 78)              Lambda (None, 80, 78)   
           Conv1D (None, 76, 1024)            Conv1D (None, 76, 1024) 
          Dropout (None, 76, 1024)           Dropout (None, 76, 1024) 
     MaxPooling1D (None, 38, 1024)      MaxPooling1D (None, 38, 1024) 
             LSTM (None, 256)                   LSTM (None, 256)      
                  \________________________________/                  
                                  |                                   
                             Merge (None, 512)                        
                             Dense (None, 128)                        
                             Dense (None, 2)                          


Model information:
=========================================
 Kernel_size: 5
 Filters: 1024
 Pool length: 2
 LSTM dropout = 0.2, 0.2
 Conv dropout: 0.500000
 No dense dropout