Training_log - 23/05/2017 10:18:48

Model name: Conv_BiLSTM
Elapsed training time: 10h:44m:03s

Training set size: 587373
Validation set size: 65263
Validation set fraction: 0.098086
Test set fraction: 0.019128

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 50
Max sequence length: 100

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.539577  1.141591  0.540398  0.809625
1   0.539586  0.808013  0.540398  0.806442
2   0.539586  0.805966  0.540398  0.805612
3   0.539586  0.805611  0.540398  0.805376
4   0.539586  0.805378  0.540398  0.805019
5   0.539586  0.805329  0.540398  0.805371
6   0.539586  0.805281  0.540398  0.805016
7   0.539586  0.805244  0.540398  0.804792
8   0.539586  0.805221  0.540398  0.804869
9   0.539586  0.805187  0.540398  0.805172
10  0.539586  0.805159  0.540398  0.805687

Validation PRF
            Female          Male  Overall Macro  Overall Micro
Precision      0.0      0.540398       0.270199       0.540398
Recall         0.0      1.000000       0.500000       0.540398
F-score        0.0      0.701634       0.350817       0.540398
Support    29995.0  35268.000000            NaN            NaN

--------------Test results---------------
loss: 0.815370 acc: 0.482600

Test PRF
           Female         Male  Overall Macro  Overall Micro
Precision     0.0     0.482596       0.241298       0.482596
Recall        0.0     1.000000       0.500000       0.482596
F-score       0.0     0.651015       0.325507       0.482596
Support    6585.0  6142.000000            NaN            NaN

--------------Model Diagram---------------
       InputLayer (None, 100)             InputLayer (None, 100)      
           Lambda (None, 100, 94)             Lambda (None, 100, 94)  
           Conv1D (None, 96, 1024)            Conv1D (None, 96, 1024) 
          Dropout (None, 96, 1024)           Dropout (None, 96, 1024) 
     MaxPooling1D (None, 48, 1024)      MaxPooling1D (None, 48, 1024) 
             LSTM (None, 256)                   LSTM (None, 256)      
                  \________________________________/                  
                                  |                                   
                             Merge (None, 512)                        
                           Dropout (None, 512)                        
                             Dense (None, 200)                        
                             Dense (None, 2)                          


Model information:
=========================================
 Kernel_size: 5
 Filters: 1024
 Pool length: 2
 LSTM dropout: 0.200000, LSTM recurrent dropout 0.200000
 Conv dropout: 0.500000
 Dense drop1 0.500000
 L1 reg on next to last layer

Extra information:
=========================================
 Remove stopwords True
 Lemmatize False
 Remove punctuation False
 Remove emoticons True
 Text is not lowercased
 Internet terms have been replaced with placeholders
 Removed 2612 tweet because they were shorter than threshold