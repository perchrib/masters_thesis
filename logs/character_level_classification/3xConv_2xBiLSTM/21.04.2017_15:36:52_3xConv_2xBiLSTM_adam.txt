Training_log - 21/04/2017 15:36:52

Model name: 3xConv_2xBiLSTM
Elapsed training time: 119 minutes

Training set size: 596499
Validation set size: 66277
Validation set fraction: 0.099999

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 30
Max sequence length: 80

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.603384  0.656890  0.618374  0.644114
1   0.625746  0.637678  0.634353  0.632193
2   0.633443  0.629341  0.634986  0.634645
3   0.638447  0.624291  0.647751  0.625157
4   0.640538  0.621284  0.643768  0.626299
5   0.643349  0.618547  0.650573  0.620023
6   0.645161  0.616483  0.652685  0.622432
7   0.647530  0.614727  0.652821  0.616709
8   0.648196  0.613724  0.653786  0.620626
9   0.649143  0.612228  0.655325  0.617724
10  0.650043  0.611106  0.655416  0.615797
11  0.651376  0.610088  0.657121  0.612293
12  0.652516  0.609251  0.659399  0.617313
13  0.652261  0.608806  0.655884  0.611859
14  0.653736  0.607812  0.656155  0.617774
15  0.654234  0.607410  0.660863  0.609197
16  0.654657  0.607298  0.659731  0.605859
17  0.655165  0.606511  0.657121  0.610465
18  0.655909  0.606108  0.660516  0.613533
19  0.655044  0.606232  0.660093  0.610893
20  0.655944  0.605872  0.659007  0.611534
21  0.655901  0.605724  0.661029  0.612027
22  0.655129  0.606416  0.657664  0.616562
23  0.655662  0.605462  0.659701  0.608921
24  0.655713  0.606090  0.659807  0.613841
25  0.655927  0.605833  0.661738  0.607474
26  0.656095  0.605733  0.659309  0.615129

--------------Model Diagram---------------
      InputLayer (None, 80)            InputLayer (None, 80)      
          Lambda (None, 80, 78)            Lambda (None, 80, 78)  
          Conv1D (None, 76, 196)           Conv1D (None, 76, 196) 
         Dropout (None, 76, 196)          Dropout (None, 76, 196) 
    MaxPooling1D (None, 38, 196)     MaxPooling1D (None, 38, 196) 
          Conv1D (None, 36, 196)           Conv1D (None, 36, 196) 
         Dropout (None, 36, 196)          Dropout (None, 36, 196) 
    MaxPooling1D (None, 18, 196)     MaxPooling1D (None, 18, 196) 
          Conv1D (None, 16, 256)           Conv1D (None, 16, 256) 
         Dropout (None, 16, 256)          Dropout (None, 16, 256) 
    MaxPooling1D (None, 8, 256)      MaxPooling1D (None, 8, 256)  
            LSTM (None, 128)                 LSTM (None, 128)     
                 \______________________________/                 
                                |                                 
                           Merge (None, 256)                      
                         Dropout (None, 256)                      
                           Dense (None, 256)                      
                         Dropout (None, 256)                      
                           Dense (None, 2)                        


Model information:
=========================================
 LSTM dropout = 0.5, 0.2
 Bi di : 128Last dense layer 256
 Dense dropout: 0.3