Training_log - 23/05/2017 05:36:06

Model name: Conv_BiLSTM
Elapsed training time: 18h:00m:17s

Training set size: 587376
Validation set size: 65264
Validation set fraction: 0.098087
Test set fraction: 0.019128

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 50
Max sequence length: 100

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.618747  0.639849  0.657116  0.597877
1   0.663131  0.594184  0.677464  0.577339
2   0.678570  0.575034  0.687577  0.560670
3   0.689248  0.561601  0.696203  0.557288
4   0.697902  0.550807  0.703098  0.544508
5   0.704244  0.541780  0.707450  0.535935
6   0.710812  0.532993  0.710882  0.531772
7   0.717031  0.525903  0.715448  0.525157
8   0.721412  0.520047  0.717746  0.522306
9   0.725009  0.514240  0.719662  0.520599
10  0.728329  0.510011  0.723860  0.516296
11  0.731756  0.505080  0.725913  0.515630
12  0.734264  0.501474  0.724657  0.514035
13  0.736807  0.497825  0.727537  0.511078
14  0.738452  0.494779  0.729054  0.509783
15  0.740681  0.492665  0.732226  0.507109
16  0.742729  0.489404  0.731062  0.507362
17  0.743602  0.487958  0.729851  0.506445
18  0.745432  0.485415  0.730617  0.505176
19  0.746258  0.483713  0.733099  0.506537
20  0.747574  0.481973  0.731812  0.504262
21  0.749050  0.480081  0.732578  0.503434
22  0.750466  0.477935  0.733789  0.501959
23  0.751522  0.477101  0.735413  0.503204
24  0.752544  0.475238  0.736225  0.501951
25  0.753032  0.474462  0.736256  0.500260
26  0.753977  0.473184  0.736225  0.499394
27  0.754752  0.472159  0.737788  0.501810
28  0.755589  0.470769  0.738585  0.499586
29  0.756090  0.470104  0.737880  0.498873
30  0.757084  0.469162  0.735689  0.500315
31  0.757845  0.466912  0.738355  0.498515
32  0.758121  0.466327  0.737834  0.500660
33  0.758046  0.466260  0.740347  0.497355
34  0.759066  0.465309  0.739596  0.499387
35  0.759932  0.464704  0.740883  0.497937
36  0.760082  0.463596  0.739703  0.497614

Validation PRF
                 Female          Male  Overall Macro  Overall Micro
Precision      0.749943      0.732884       0.741413       0.739703
Recall         0.651548      0.814838       0.733193       0.739703
F-score        0.697292      0.771691       0.734491       0.739703
Support    30030.000000  35234.000000            NaN            NaN

--------------Test results---------------
loss: 0.750400 acc: 0.591500

Test PRF
                Female         Male  Overall Macro  Overall Micro
Precision     0.615925     0.569862       0.592894       0.591498
Recall        0.559150     0.626180       0.592665       0.591498
F-score       0.586166     0.596695       0.591431       0.591498
Support    6585.000000  6142.000000            NaN            NaN

--------------Model Diagram---------------
       InputLayer (None, 100)             InputLayer (None, 100)      
           Lambda (None, 100, 94)             Lambda (None, 100, 94)  
           Conv1D (None, 96, 1024)            Conv1D (None, 96, 1024) 
          Dropout (None, 96, 1024)           Dropout (None, 96, 1024) 
     MaxPooling1D (None, 48, 1024)      MaxPooling1D (None, 48, 1024) 
             LSTM (None, 256)                   LSTM (None, 256)      
                  \________________________________/                  
                                  |                                   
                             Merge (None, 512)                        
                           Dropout (None, 512)                        
                             Dense (None, 200)                        
                             Dense (None, 2)                          


Model information:
=========================================
 Kernel_size: 5
 Filters: 1024
 Pool length: 2
 LSTM dropout: 0.200000, LSTM recurrent dropout 0.200000
 Conv dropout: 0.500000
 Dense drop1 0.500000
Extra information:
=========================================
 Remove stopwords True
 Lemmatize False
 Remove punctuation False
 Remove emoticons False
 Text is not lowercased
 Internet terms have been replaced with placeholders
 Removed 2608 tweet because they were shorter than threshold