Training_log - 02/05/2017 19:23:31

Model name: Conv_BiLSTM
Elapsed training time: 2h:36m:15s

Training set size: 530222
Validation set size: 66277
Validation set fraction: 0.099999
Test set fraction: 0.099999

Hyperparameters
=========================================
Optimizer: adam
Batch size: 256
Max number of epochs: 50
Max sequence length: 55

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.608324  0.651113  0.633825  0.625122
1   0.639692  0.620959  0.649396  0.611591
2   0.653496  0.605431  0.657739  0.599568
3   0.664261  0.593664  0.663594  0.592873
4   0.672978  0.583321  0.665208  0.592151
5   0.680781  0.574046  0.668995  0.585358
6   0.687442  0.566376  0.676570  0.579314
7   0.692657  0.559093  0.678410  0.576718
8   0.697589  0.552242  0.682424  0.573307
9   0.703019  0.546304  0.683450  0.572277
10  0.706868  0.540389  0.686588  0.569839
11  0.711596  0.535427  0.686271  0.568561
12  0.716021  0.529449  0.689259  0.566640
13  0.720204  0.524187  0.690828  0.567839
14  0.722101  0.520701  0.691643  0.564122
15  0.726264  0.515301  0.693936  0.562163
16  0.729576  0.511134  0.695973  0.562820
17  0.731927  0.506788  0.697723  0.563205
18  0.736688  0.502232  0.697361  0.561302
19  0.738398  0.499577  0.698055  0.565140
20  0.740761  0.496392  0.699504  0.561705
21  0.743862  0.492271  0.695460  0.570158

--------------Test results---------------
loss: 0.573760acc: 0.693650

--------------Model Diagram---------------
       InputLayer (None, 55)              InputLayer (None, 55)       
           Lambda (None, 55, 78)              Lambda (None, 55, 78)   
           Conv1D (None, 49, 1024)            Conv1D (None, 49, 1024) 
          Dropout (None, 49, 1024)           Dropout (None, 49, 1024) 
     MaxPooling1D (None, 24, 1024)      MaxPooling1D (None, 24, 1024) 
             LSTM (None, 256)                   LSTM (None, 256)      
                  \________________________________/                  
                                  |                                   
                             Merge (None, 512)                        
                             Dense (None, 128)                        
                             Dense (None, 2)                          


Model information:
=========================================
 Kernel_size: 7
 Filters: 1024
 Pool length: 2
 Conv dropout: 0.500000
 LSTM dropout = 0.2, 0.2
 No dense dropout