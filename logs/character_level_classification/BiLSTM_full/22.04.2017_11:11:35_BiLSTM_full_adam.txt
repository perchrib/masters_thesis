Training_log - 22/04/2017 11:11:35

Model name: BiLSTM_full
Elapsed training time: 649 minutes

Training set size: 596499
Validation set size: 66277
Validation set fraction: 0.099999

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 30
Max sequence length: 80

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.552905  0.685838  0.575630  0.676624
1   0.570925  0.678469  0.581876  0.673470
2   0.578103  0.674224  0.587760  0.667125
3   0.583009  0.670228  0.594535  0.659175
4   0.588045  0.666280  0.601792  0.658106
5   0.592675  0.662845  0.606259  0.652614
6   0.596651  0.659345  0.606666  0.647614
7   0.601190  0.655918  0.611660  0.644695
8   0.605049  0.653002  0.617982  0.639932
9   0.608519  0.649923  0.614663  0.639339
10  0.610566  0.647711  0.626944  0.630970
11  0.613451  0.645663  0.626100  0.633288
12  0.614987  0.643709  0.632361  0.628709
13  0.618011  0.641424  0.634473  0.626394
14  0.619879  0.640079  0.633810  0.624821
15  0.621525  0.638220  0.638819  0.621628
16  0.623661  0.636507  0.633448  0.624192
17  0.623974  0.635663  0.638789  0.623038
18  0.626400  0.633691  0.642893  0.617868
19  0.627401  0.633173  0.643677  0.617101
20  0.628906  0.631532  0.646514  0.613861
21  0.629354  0.630572  0.643421  0.613773
22  0.631082  0.629130  0.648400  0.611625
23  0.631792  0.628003  0.647072  0.611687
24  0.633595  0.627176  0.646514  0.612387
25  0.633748  0.626309  0.647993  0.610748
26  0.635828  0.625105  0.650769  0.611219
27  0.636162  0.624279  0.653771  0.607545
28  0.636009  0.624033  0.653470  0.605715
29  0.637768  0.623181  0.651629  0.607486

--------------Model Diagram---------------
     InputLayer (None, 80)          InputLayer (None, 80)     
         Lambda (None, 80, 77)          Lambda (None, 80, 77) 
           LSTM (None, 128)               LSTM (None, 128)    
                \____________________________/                
                              |                               
                         Merge (None, 256)                    
                       Dropout (None, 256)                    
                         Dense (None, 256)                    
                       Dropout (None, 256)                    
                         Dense (None, 2)                      


Model information:
=========================================
 LSTM dropout = 0.2, 0.2