Training_log - 16/04/2017 20:54:58

Model name: BiLSTM_full
Elapsed training time: 414 minutes

Training set size: 596499
Validation set size: 66277
Validation set fraction: 0.099999

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 20
Max sequence length: 80

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.543793  0.688482  0.539735  0.687503
1   0.544769  0.687783  0.537758  0.689666
2   0.554093  0.684539  0.562971  0.680426
3   0.564432  0.680807  0.571767  0.674028
4   0.565506  0.680426  0.564902  0.679422
5   0.566045  0.679140  0.587323  0.668636
6   0.568615  0.677864  0.572793  0.671128
7   0.571743  0.675943  0.576942  0.669658
8   0.574563  0.673753  0.591623  0.666188
9   0.578392  0.671870  0.593871  0.664507
10  0.579763  0.669821  0.597281  0.656828
11  0.580786  0.668947  0.594927  0.654736
12  0.581828  0.668663  0.612701  0.652846
13  0.584661  0.666572  0.611886  0.651883
14  0.585734  0.665872  0.619566  0.649750
15  0.587488  0.664815  0.618706  0.646372
16  0.587562  0.664036  0.614391  0.650282
17  0.589039  0.662610  0.622101  0.640294
18  0.590705  0.661958  0.624319  0.640043
19  0.591978  0.660204  0.618601  0.644059

--------------Model Diagram---------------
     InputLayer (None, 80)          InputLayer (None, 80)     
         Lambda (None, 80, 77)          Lambda (None, 80, 77) 
           LSTM (None, 512)               LSTM (None, 512)    
                \____________________________/                
                              |                               
                         Merge (None, 1024)                   
                       Dropout (None, 1024)                   
                         Dense (None, 128)                    
                       Dropout (None, 128)                    
                         Dense (None, 2)                      


Extra information:
=========================================
 LSTM dropout = 0.5, 0.2