Training_log - 21/04/2017 20:27:39

Model name: BiLSTM_full
Elapsed training time: 543 minutes

Training set size: 596499
Validation set size: 66277
Validation set fraction: 0.099999

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 30
Max sequence length: 80

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.559168  0.683244  0.576474  0.674845
1   0.573156  0.676595  0.587323  0.668388
2   0.581210  0.671358  0.593569  0.661626
3   0.588542  0.665601  0.596949  0.656146
4   0.593381  0.661233  0.604539  0.651334
5   0.598070  0.657397  0.607722  0.645943
6   0.604097  0.653154  0.613380  0.643411
7   0.609134  0.648963  0.625858  0.635679
8   0.612724  0.645182  0.625888  0.632268
9   0.616913  0.641569  0.632376  0.626072
10  0.620878  0.638828  0.633810  0.624888
11  0.623750  0.635819  0.640690  0.619176
12  0.626445  0.633778  0.639256  0.617365
13  0.627667  0.631103  0.643798  0.613366
14  0.630712  0.629008  0.636737  0.617359
15  0.633089  0.626770  0.646755  0.611784
16  0.633957  0.625164  0.648430  0.613724
17  0.636256  0.623702  0.651704  0.606374
18  0.638522  0.621594  0.652836  0.604392
19  0.639470  0.620112  0.651946  0.604418
20  0.641148  0.617901  0.651870  0.603224
21  0.643029  0.617166  0.659746  0.604678
22  0.643723  0.615415  0.659143  0.601123
23  0.645413  0.614689  0.661391  0.597941
24  0.647354  0.613071  0.659309  0.598014
25  0.647123  0.612466  0.662809  0.596862
26  0.648568  0.610992  0.661315  0.595479
27  0.649832  0.609899  0.662100  0.596169
28  0.650802  0.609208  0.663971  0.594216
29  0.652045  0.608017  0.657121  0.598593

--------------Model Diagram---------------
     InputLayer (None, 80)          InputLayer (None, 80)     
         Lambda (None, 80, 78)          Lambda (None, 80, 78) 
           LSTM (None, 256)               LSTM (None, 256)    
                \____________________________/                
                              |                               
                         Merge (None, 512)                    
                       Dropout (None, 512)                    
                         Dense (None, 512)                    
                       Dropout (None, 512)                    
                         Dense (None, 2)                      


Model information:
=========================================
 LSTM dropout = 0.2, 0.2