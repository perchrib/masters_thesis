Training_log - 16/04/2017 02:41:42

Model name: BiLSTM_full
Elapsed training time: 141 minutes

Training set size: 596499
Validation set size: 66277
Validation set fraction: 0.099999

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 20
Max sequence length: 80

-----------Training statistics-----------
        acc      loss   val_acc  val_loss
0  0.541528  0.690440  0.539976  0.690005
1  0.541961  0.689660  0.539976  0.689965
2  0.541994  0.689637  0.539976  0.689960
3  0.541961  0.689668  0.539976  0.690038
4  0.542013  0.689641  0.539976  0.690048
5  0.541987  0.689654  0.539976  0.689961

--------------Model Diagram---------------
     InputLayer (None, 80)          InputLayer (None, 80)     
         Lambda (None, 80, 77)          Lambda (None, 80, 77) 
           LSTM (None, 512)               LSTM (None, 512)    
                \____________________________/                
                              |                               
                         Merge (None, 1024)                   
                       Dropout (None, 1024)                   
                         Dense (None, 128)                    
                       Dropout (None, 128)                    
                         Dense (None, 2)                      


Extra information:
=========================================
 No consume_less