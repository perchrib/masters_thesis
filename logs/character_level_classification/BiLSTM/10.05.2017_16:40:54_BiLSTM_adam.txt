Training_log - 10/05/2017 16:40:54

Model name: BiLSTM
Elapsed training time: 18h:48m:46s

Training set size: 530222
Validation set size: 66277
Validation set fraction: 0.099999
Test set fraction: 0.099999

Hyperparameters
=========================================
Optimizer: adam
Batch size: 128
Max number of epochs: 50
Max sequence length: 80

-----------Training statistics-----------
         acc      loss   val_acc  val_loss
0   0.558215  0.683261  0.575373  0.673552
1   0.567542  0.678128  0.581227  0.670340
2   0.581202  0.670420  0.587957  0.664591
3   0.587550  0.665818  0.596979  0.659126
4   0.594276  0.660473  0.610845  0.650494
5   0.600058  0.656440  0.613637  0.646627
6   0.604600  0.652542  0.622056  0.637664
7   0.611003  0.646947  0.626990  0.633108
8   0.613896  0.644321  0.629932  0.628871
9   0.620093  0.639117  0.634232  0.623585
10  0.623967  0.635607  0.639619  0.619430
11  0.627186  0.631941  0.642983  0.616516
12  0.630587  0.628803  0.644945  0.612639
13  0.633484  0.625938  0.645443  0.611981
14  0.634876  0.623804  0.649034  0.607593
15  0.639057  0.620686  0.650708  0.604755
16  0.640121  0.618637  0.652957  0.603029
17  0.642844  0.616444  0.654224  0.600950
18  0.644106  0.615556  0.654179  0.599727
19  0.644883  0.613963  0.659580  0.597964
20  0.646542  0.611677  0.655340  0.600246
21  0.648900  0.610251  0.658041  0.597716
22  0.651133  0.607819  0.659641  0.594553
23  0.651427  0.607080  0.661436  0.593860
24  0.651640  0.607141  0.660893  0.593324
25  0.652578  0.606612  0.663805  0.591810
26  0.653598  0.604880  0.662900  0.591273
27  0.655116  0.603488  0.665178  0.590370
28  0.655718  0.602507  0.665223  0.588389
29  0.657734  0.600353  0.666460  0.588898
30  0.659892  0.598136  0.667849  0.585393
31  0.661289  0.596873  0.667185  0.586602
32  0.662189  0.595989  0.668331  0.585029
33  0.663305  0.594880  0.669840  0.583814
34  0.663911  0.593780  0.672013  0.581906
35  0.666928  0.591113  0.672194  0.581176
36  0.666174  0.590801  0.672134  0.581171
37  0.666342  0.590811  0.671289  0.581565
38  0.667862  0.589436  0.672632  0.579325
39  0.667858  0.589566  0.674005  0.579555
40  0.668367  0.588475  0.674397  0.579255
41  0.670813  0.586947  0.676751  0.577781
42  0.669991  0.586393  0.673718  0.578600
43  0.671605  0.584940  0.677430  0.576880
44  0.672484  0.584607  0.676766  0.576025
45  0.673839  0.582185  0.679195  0.574714
46  0.674048  0.582299  0.676343  0.577745
47  0.673793  0.582536  0.678093  0.575924
48  0.675227  0.581410  0.678214  0.573895
49  0.675823  0.580184  0.678033  0.574043

--------------Test results---------------
loss: 0.573560acc: 0.681220

--------------Model Diagram---------------
     InputLayer (None, 80)          InputLayer (None, 80)     
         Lambda (None, 80, 78)          Lambda (None, 80, 78) 
           LSTM (None, 256)               LSTM (None, 256)    
                \____________________________/                
                              |                               
                         Merge (None, 512)                    
                         Dense (None, 2)                      


Model information:
=========================================
 LSTM dropout: 0.200000, LSTM recurrent dropout 0.200000
 No merge dropout
Extra information:
=========================================
 Stopwords removed
 All Internet terms are replaced with tags